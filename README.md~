# Online players behavior

Este repositório faz parte de um projeto de mestrado. Esse projeto visa descobrir padrões no comportamento de jogadores de League of Legends que caracterizem jogadores com alto rendimento de jogadores com baixo rendimento. Portanto, será utilizado Python como linguagem principal para realizar o projeto.

## TODO

* Criar esqueleto básico do projeto em python
* Pesquisar libs para acessar APIs com Python
* Estudar API do League of Legends (LOL)
* Estudar sobre alguns algoritmos de aprenfizagem não supervisionada
* Capturar algumas amostras de dados do LOL
* Testar bibliotecas data mining ou machine learning
* Realizar experimentos mais elaborados com os algoritmos
* Analisar resultados


* http://www.researchgate.net/post/When_and_why_do_we_need_data_normalization
In data mining, we can consisted the four main steps:
1. Smoothing data
2. Generalization of data 
3. Normalization of data
4. Construction of new characteristics

##LOL

 features such as a player’s character choice, team characters composition, and certain player behaviors. 
datasets on game histories that includes information such as performance statistics (e.g., how many actions of a specific type that a character has used), composition of the team (i.e., the specific characters each team has chosen to match-up against the other), and the results of the match (wins/losses, important objectives obtained during the game, etc.).

 specifically K-means (w/ cross validation) or DP-means [KJ12], to cluster player character behaviors and team compositions that are statistically more successful against a given opposing team composition

## Data Mining and Analysis

* data mining is part of a larger knowledge discovery process, which includes pre-processing tasks such as data extraction, data cleaning, data fusion, data reduction and feature construction,
* post-processing steps such as pattern and model interpretation, hypothesis confirmation and generation, and so on.
* Given a dataset of n points in a d-dimensional space, the fundamental analysis and mining tasks: exploratory data analysis, frequent pattern discovery, data clustering, and classification models.


**Exploratory data analysis** aims to explore the numeric and categorical attributes of the data individually or jointly to extract key characteristics of the data sample via statistics that give information about the centrality, dispersion, and so on. Another goal of exploratory analysis is to reduce the amount of data to be mined. For instance, feature selection and dimensionality reduction methods are used to select the most important dimensions, discretization methods can be used to reduce the number of values of an attribute, data sampling methods can be used to reduce the data size, and so on.


the multivariate normal distribution, which iswidely used as the default parametric model for data in both classification and clustering

Chapter 2 - basic statistical analysis of univariate and multivariate numeric data. measures of central tendency such as mean, median, and mode, and then we consider measures of dispersion such as range, variance, and covariance. The multivariate normal distribution, which iswidely used as the default parametric model for data in both classification and clustering
, 3 - how categorical data can be modeled via the multivariate binomial and the multinomial distributions. dependence between categorical attributes
, 5 - Kernel methods are then introduced in Chapter 5, which provide new insights and connections between linear, nonlinear, graph, and complex data mining tasks
, 6 - Chapter 6 we consider the peculiarities of high-dimensional space, colorfully referred to as the curse of dimensionality. In
7 - Chapter 7 we describe the widely used dimensionality reduction methods such as principal component analysis (PCA) and singular value decomposition (SVD). PCA finds the optimal k-dimensional subspace that captures most of the variance in the data.

## EDA

### UNIVARIATE ANALYSIS 

the probability density or mass function f (x) and the cumulative distribution function F(x), for attribute X, are both unknown. we can estimate these distributions directly from the data sample, which also allow us to compute statistics to estimate several important population parameters.

Measures of Central Tendency: These measures given an indication about the concentration of the probability mass, the “middle” values, and so on.

Measures of Dispersion: The measures of dispersion give an indication about the spread or variation in the values of a random variable

### BIVARIATE ANALYSIS

In bivariate analysis, we consider two attributes at the same time.We are specifically interested in understanding the association or dependence between them, if any.

-> UNIVARIATE ANALYSIS++

Measures of Association: Covariance


**kernel methods**

- Before we can mine data, it is important to first find a suitable data representation that facilitates data analysis.
extract or construct a set of attributes or features, so thatwe can represent the data instances asmultivariate vectors
Kernel methods avoid explicitly transforming each point x in the input space into the mapped point φ(x) in the feature space.

**Dimensionality reduction**

it is important to check whether the dimensionality can be reduced while preserving the essential properties of the full data matrix. This can aid data visualization as well as data mining.

**itemset minig**

association rules -> team who pick hero x also pick hero y...

## Links aleatórios

* [Mining the Social Web, 2nd Edition](http://shop.oreilly.com/product/0636920030195.do?cmp=af-strata-books-video-product_cj_0636920030195_7133220)
* [Github of Mining the Social Web, 2nd Edition](https://github.com/fernandojunior/Mining-the-Social-Web-2nd-Edition)
* [What are the best Python 2.7 modules for data mining?](http://www.quora.com/What-are-the-best-Python-2-7-modules-for-data-mining)
* [Best Python modules for data mining](http://www.kdnuggets.com/2012/11/best-python-modules-for-data-mining.html)
* [A Programmer's Guide to Data Mining](http://guidetodatamining.com/)
* [Gaming Analytics Summit 2015, San Francisco – Day 2 Highlights](http://www.kdnuggets.com/2015/05/gaming-analytics-summit-san-francisco-highlights-day2.html#.VVES4duzsWk.linkedin)
* [scikit-learn](http://scikit-learn.org/stable/)
* [plotly](https://plot.ly/plot)
* Tableau
* https://github.com/fernandojunior/TeamCompML
* https://github.com/fernandojunior/Riot-Watcher
* https://github.com/Kruptein/lolapi
* https://github.com/p-ob/lolPy
* https://github.com/mikamai/ruby-lol

## Autor

Fernando Felix do Nascimento Junior

## Orientador

Leandro Balby Marinho

## License

Released under [the MIT license](https://github.com/dndlab/dndlab.github.io/blob/master/LICENSE)
